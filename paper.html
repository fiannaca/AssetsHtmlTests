<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>AACrobat: Using Mobile Devices to Lower Communication Barriers and Provide Autonomy with Gaze-Based AAC</title>
    <link rel="stylesheet" type="text/css" href="css/pub.css">
    <style>

      .reminder {
        margin-top: 32pt;
        text-align: center;
        font-family: Helvetica;
        font-size: 18pt;
        font-weight: bold;
      }

      sup {
        font-size: 8pt;
      }

      ol, ol li {
        margin-left: 10px;
      }

      figure figcaption, table caption {
        text-align: justify;
      }

    </style>
  </head>
  <body>
    <h1 class="title counter-skip">AACrobat: Using Mobile Devices to Lower Communication Barriers and Provide Autonomy with Gaze-Based AAC</h1>
    <header>
      <div class="authors col-4">
        <div class="author">
          <div>Alexander Fiannaca<sup>1,2</sup></div>
        </div>
        <div class="author">
          <div>Ann Paradiso<sup>1</sup></div>
        </div>
        <div class="author">
          <div>Mira Shah<sup>1</sup></div>
        </div>
        <div class="author">
          <div>Meredith Ringel Morris<sup>1</sup></div>
        </div>
      </div>
      <div class="authors col-2">
        <div class="author">
          <div><sup>1</sup>Microsoft Research</div>
          <div>Redmond, USA</div>
          <div>{annpar,mshah,merrie}@microsoft.com</div>
        </div>
        <div class="author">
          <div><sup>2</sup>University of Washington</div>
          <div>Seattle, USA</div>
          <div>fiannaca@cs.uw.edu</div>
        </div>
      </div>
    </header>

    <div class="copyright">
      <div>
        <div>Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee.</div>
        <div><em>Conference’10, Month 1–2, 2010, City, State, Country.</em></div>
        <div>Copyright 2010 ACM 1-58113-000-0/00/0010 …$15.00.</div>
      </div>
    </div>

    <div class="abstract counter-skip">
      <h1>Abstract</h1>
      <p>Gaze-based alternative and augmentative communication (AAC) devices provide users with neuromuscular diseases the ability to communicate with other people through only the movement of their eyes. These devices suffer from slow input, causing a host of communication breakdowns to occur during face-to-face conversations. These breakdowns lead to decreased user autonomy, conversation quality, and communication partner engagement. Attempts to improve communication through these devices has mainly focused on throughput and rate enhancement, though this has only attained meager results to date. In this work, we address this issue from the top down by considering AAC devices as a form of groupware and designing interactions around this groupware that facilitate better conversations for all involved communicators. We first present qualitative findings on issues with gaze-based AAC and end-user communication preferences; we identify several design guidelines for improving these systems and then present AACrobat, a system that embodies these guidelines and introduces novel interactions by extending gaze-based AAC devices with a mobile companion app. Finally, we present early feedback on AACrobat through three case studies of users with ALS.</p>

      <h2>Categories and Subject Descriptors</h2>
      <p>K.4.2 Social Issues: Assistive Technologies for Persons with Disabilities; H.5.3 Group and Organization Interfaces: Collaborative Computing</p>

      <h2>Keywords</h2>
      <p>Gaze-Based AAC; Amyotrophic Lateral Sclerosis; ALS.</p>
    </div>

    <h1>Introduction</h1>
    <section>
      <p>Amyotrophic Lateral Sclerosis (ALS) is a neuromuscular disease characterized by the degeneration and death of motor neurons (those that control the movement of muscles), ultimately leading to complete paralysis and death [25]. The progression of ALS leads to the loss of both mobility and the ability to speak, though patients often retain control of the muscles that are responsible for movement of the eyes [2]. Unsurprisingly, therefore, use of gaze-based alternative and augmentative communication technologies is critical for improving or maintaining the quality of life of people living with ALS [2]. These symptoms necessitate the use of alternative and augmentative communication (AAC) technologies designed around eye gaze input to allow people with ALS to communicate. These AAC technologies range from low-tech to high-tech, and AAC users often use a set of different devices from this spectrum depending on the needs and constraints of the moment [22]. Low-tech solutions typically involve communication boards, which are clear plastic boards with letters or symbols on them that are held by a communication partner; the ALS patient gazes at the relevant symbol on the board, and their gaze is manually interpreted by the partner (e.g., e-tran boards [24], Vocal Eyes [3]). High-tech solutions for gaze-based communication involve the use of eye trackers to control computer interfaces (e.g., Tobii Dynavox [31], PRC Accent [7]). With these high-tech devices, users typically use gaze control to type a message, and then gaze-activate a button to play that message out loud via the device’s speakers, using text-to-speech rendering technology. Use of these devices is reliant upon a number of environmental and personal factors including the amount of ambient sunlight (which causes infrared interference), the user’s use of glasses, and medications that affect pupil dilation. Unfortunately, even when users are able to effectively use these high-tech gaze-based AAC devices communication is extremely slow  (about 10 words per minute) [23]. The stark asymmetry in communication rates between the AAC device user and their naturally speaking communication partners limits the type of communication users can have through these devices and causes significant communication breakdowns.</p>

      <p>In this paper, we present AACrobat, a system consisting of extensions to an eye-gaze keyboard and a mobile companion application that are designed to alleviate many of the issues that arise due to the inherently slow rate of communication with gaze-based AAC devices. This paper presents several research contributions:</p>

      <ol>
        <li>Reframing the research perspective surrounding AAC communication to expand the focus beyond low-level technical issues (e.g., gaze sensing, rate enhancement), instead taking a perspective of AAC devices as a form of groupware and considering designing systems with roles to facilitate better feedthrough between participants.</li>
        <li>Qualitative results providing insights into the often conflicting desires of AAC device users and their communication partners when it comes to how the two mediate communication through the AAC device.</li>
        <li>The AACrobat system, a set of AAC device extensions and a mobile app that introduce novel interactions designed to address communication challenges for gaze-based AAC device users and their communication partners.</li>
        <li>The gathering of preliminary feedback about AACrobat from users with ALS and their communication partners.</li>
      </ol>
    </section>

    <h1>Related Work</h1>
    <section>
      <p>The use of AAC devices is critical in the care of people with ALS [4]. The only AAC devices applicable to people with ALS are those with input modalities requiring the fewest voluntary muscle movements [4]. Hill et al. [14] indicated that the fact that gaze input is usable throughout the duration of the progression of the disease has the potential to significantly improve patients’ quality of life  [6]. It has also been shown that the use of eye tracking communication devices decreases the burden caregivers feel in caring for people with ALS [15].</p>
      
      <p>Unfortunately, the process of gaze tracking is difficult and highly error prone, thus far leading to AAC systems that are very slow in comparison to the rate at which human speech normally occurs. Yorkston et al. [36] found that the average rate of speech of adults without disabilities was 190 words per minute (wpm). High-tech gaze-based AAC devices produce communication more than an order of magnitude slower than this [13]. On eye typing systems with dwell-based clicking (focusing on a target for a fixed period of time generates a click), able-bodied users can reach up to 20 wpm with an appropriately adjusted dwell time [22]. Dwell-based systems suffer an inherent cap on throughput due to the fact that users must fixate upon targets for some non-zero threshold of time in order to activate or click them.</p>
      
      <p>It has been suggested that dwell-free eye typing systems that use “gaze gestures” analogous to swipe-style keyboards [19] could be developed with the theoretical potential to reach throughputs of up to 46 wpm (based on observations of a simulation with a perfect dwell-free gaze recognizer) [18]. To the contrary of these simulated results, the most recent dwell-free systems achieve much lower throughput rates in practice: the Filteryedping system had a throughput of 7.6 wpm for users with ALS or Duchenne Muscular Dystrophy [29], and the EyeSwipe system had a throughput of 11.7 wpm for able-bodied users [20]. The Tobii Dynavox Communicator 5 [37], a commercial dwell-free system claiming up to a 100% increase in throughput on a per user basis, became available in the summer of 2015, but independent metrics reporting end-user throughput with this system are not yet available due to its novelty. Other non-keyboard-based AAC systems such as Dasher [33,34] and EyeWrite [35] have attempted to address the throughput issue, but none have succeeded in breaking past the current cap of approximately 20 wpm for users with motor impairments. Additionally, rate enhancement techniques such as word prediction [10,13,32], context-awareness [17], and co-construction [28,30] have attempted to address this problem, but have only resulted in minor throughput improvements. As an example, Paepke et. al. created a rate enhancement system that displays an AAC user’s current text and a tree of word predictions to communication partners on a computer screen, allowing partners to guess out loud at what the AAC user is trying to say [28]. In a similar project, Roark verified that communication partners could effectively enhance communication rate by guessing to complete words being typed on a computer screen [30]. Unfortunately, neither of these studies evaluated their systems with AAC users or studied the impact of this “guessing out loud” interaction on conversation dynamics or patient autonomy.</p>
      
      <p>The research community of AAC technologists has dedicated a significant amount of work towards enhancing the throughput rate of gaze-based AAC devices; this is an important challenge, though even doubling or tripling of gaze-based AAC throughput would still result in communication rates far below those of conversational speech. Thus, while improving throughput is important, it is also important to consider how to address the myriad other communication problems that result from low throughput rates. For instance, it takes a long time for users to construct contributions to group conversations due to the throughput problem, resulting in AAC device users contributing their thoughts after the topic of the conversation has already shifted. These out-of-context contributions cause conversations to break down, making it difficult for AAC device users to participate in group conversations,  which contributes to their isolation [9,27]. Furthermore, this inability to rapidly produce utterances through AAC devices leads to a loss of conversational control for AAC device users [26] (i.e., it is difficult for AAC users to direct conversations). Fulcher [9] showed that using shared screens for AAC devices can help to improve communication; however, this presents potential privacy issues in that communication partners see the entirety of the information present in the AAC device interface.</p>
      
      <p>A majority of prior work in improving communication through gaze-based AAC has focused on addressing communication issues in a bottom-up manner via throughput and rate enhancement, rather than designing the system to facilitate effective communication given the low throughput inherent in the devices. With the exception of the study of co-construction [28,30], previous work in this field has viewed the design of gaze-based AAC systems without regard to the role of communication partners in facilitating effective communication. As described by Fulcher [9], this bottom-up approach is one-sided, in that it puts the burden of facilitating effective communication solely on the AAC device user without considering the social aspect inherent in interpersonal communication. Acknowledging a similar issue for aphasia patients, Kagan presented the supported communication intervention for people with aphasia and their communication partners [16]. Supported conversation focuses on creating a feeling of autonomy for the person with aphasia while specifically teaching communication dyads to share the communication load rather than simply training the person with aphasia to develop independent communication skills. In practice, supported conversation involves conceptual training in which communication partners are taught both what it may be like to personally experience aphasia and the impact it can have for them to learn skills for supporting their aphasic communication partners, followed by hands-on instruction and practice of communication skills with people with aphasia. In this research, we take inspiration from both the motivation behind supported conversation and from the concept of groupware [1], thinking of AAC software as a shared workspace through which effective communication should be enabled by sharing the communication burden among all interlocutors. This perspective inspired our work to explore methods of facilitating better communication by looking specifically at how communication partners currently interact with AAC users and their software and how these interactions could be augmented via explicit feedthrough mechanisms [1] to improve communication.</p>
    </section>

    <h1>Formative Study</h1>
    <section>
      <table style="float: column-top;">
        <caption>Responses to the question, "How do you try to help the AAC device/software user?" for the communication partners who indicated they have attempted to help AAC users.</caption>
        <thead>
          <tr>
            <th>Individual Responses</th>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td>“Read over shoulder, sometimes hit delete word or backspace for him”</td>
          </tr>
          <tr>
            <td>“Guess the end of a sentence before it has been completely typed and spoken”</td>
          </tr>
          <tr>
            <td>“Looking at typed message. Trying to finish sentence/thought”</td>
          </tr>
          <tr>
            <td>“Sometimes he just needs a few words and I know him well enough that I get what he's saying it save [sic] us both time.”</td>
          </tr>
          <tr>
            <td>“Making questions easier to answer, being very specific.”</td>
          </tr>
          <tr>
            <td>“I give them my advice based off my own experience”</td>
          </tr>
        </tbody>
      </table>

      <p>To better understand the issues faced by both gaze-based AAC users and their communication partners during communication, we conducted a formative study to obtain qualitative feedback from the target user groups. We designed this formative study to explore communication issues as they relate to the interaction between AAC users and various types of communication partners.</p>
      
      <h2>Method</h2>
      <p>We created two online questionnaires to gather qualitative data: one for gaze-based AAC users, and one for their communication partners . We chose an online questionnaire as the data-gathering method because it was suited to the unique constraints of working with ALS patients – the format allowed respondents to answer questions at their own pace, take rest breaks, and avoid the need to travel. Participants were recruited through an email list for an ALS organization in our local metropolitan area consisting of people with ALS and family members and caregivers of people with ALS.</p>

      <p>The AAC User questionnaire contained 33 questions and took respondents twenty-seven minutes on average to complete. Inclusion criteria were that users must both be diagnosed with a degenerative neuromuscular disease and must own a gaze-based AAC device. Eight people (six male) completed the AAC User questionnaire; respondents’ ages ranged from 44 to 57 years (mean 51.5). All respondents had been diagnosed with ALS in the last ten years and completed the questions without the assistance of a caregiver.</p>
      
      <p>The Communication Partner questionnaire contained 29 questions and took respondents thirteen minutes on average to complete. The only inclusion criterion was that participants must know and communicate with someone who has a degenerative neuromuscular disease and uses a gaze-based AAC device. Nine people total (all female) completed the Communication Partner questionnaire; respondents’ ages ranged from 42 to 68 years (mean 54.8). All respondents self-identified as spouses, family members, caregivers, and/or friends of people with ALS.</p>
      
      <p>Note that this relatively small sample size is not surprising given (1) the low incidence rate of ALS, which affects only 2 people per 100,000 [25]; (2) the technical difficulty for ALS patients dependent on gaze-based AAC in answering questions autonomously; and (3) the additional demands on ALS patients’ time, with respect to issues such as extreme fatigue and the desire to save energy for high-priority interactions given their extremely shortened lifespan. As with many studies and methods, readers should be aware that there may be self-selection biases; for example, it may be the case that respondents with the skill or motivation to complete an online questionnaire may have different perspectives and experiences than those who did not participate.</p>

      <table style="float: column-top;">
        <caption>Responses from AAC users indicating their level of comfort with communication partners attempting to help them communicate (N = neutral, SU = somewhat uncomfortable, VU = very uncomfortable). Note that the remaining two options, comfortable and very comfortable, were never chosen.</caption>
        <thead>
          <tr>
            <th>Response/Reason</th>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td>(SU) “It erodes one’s confidence over time. It prevents nuanced conversation by cutting it short when person reading or guessing thinks they know the nature of the full communication from a few words.”</td>
          </tr>
          <tr>
            <td>(N) “It doesn't bother me there trying to help and most of the time it turns into a game. There are times it does start to get on my nerves.”</td>
          </tr>
          <tr>
            <td>(VU) “It's not socially acceptable.  Makes me more aware of my losses in capabilities from this disease…”</td>
          </tr>
          <tr>
            <td>(N) “It depends on the situation. If I am asking for something or simply conveying information, I am very comfortable with someone anticipating my comments but if I am in a conversation with someone or a group of people, I am very uncomfortable with someone speaking for me and/or reading over my shoulder.”</td>
          </tr>
          <tr>
            <td>(SU) “Because I’ve always been a detailed, long story type guy.”</td>
          </tr>
          <tr>
            <td>(SU) “I need independence.”</td>
          </tr>
        </tbody>
      </table>

      <h2>Findings</h2>

      <h3>Partners' Roles</h3>
      <p>Of the nine respondents who completed the entire Communication Partner questionnaire, six indicated that they had attempted to help gaze-based AAC users to communicate or communicate faster in the past. Of these six, five indicated that this was related to communication problems the AAC user experienced, including the AAC user getting left behind in conversations that move faster than they are able to generate speech (five respondents), the AAC device having a technical issue rendering it temporarily unusable (four respondents), the AAC device generating nonsensical output (two respondents), and message generation taking so long that they were unsure if the device was broken or not (two respondents).</p>
    
      <p>Of the six respondents to the Communication Partner questionnaire who indicated that they help AAC users to communicate or communicate faster, all six described themselves as having a moderator and/or facilitator role when communicating with the AAC user. Examples of these responses can be seen in Table 1. Additionally, when asked how comfortable the communication partners were with performing these actions to try and help the AAC user, five of the six respondents indicated on a five-point scale that they were either “neutral,” “somewhat comfortable,” or “very comfortable.” Likewise, five of the six respondents indicated that they believed the AAC user to be either “neutral,” “somewhat comfortable,” or “very comfortable” with the assistance they rendered.</p>
      
      <figure style="float: column-top;">
        <img src="img/figure1.png" id="figure1" style="width: 80%;">
        <figcaption>Subjective ratings of AAC users' comfort level with communication partners attempting to help them communicate broken down by relationship with 0 being "Very Uncomfortable" and 4 being "Very Comfortable." Bars indicate standard error.</figcaption>
      </figure>

      <h3>Autonomy</h3>
      <p>Interestingly, the communication partners’ views were in contrast to those of the AAC users. Of the six respondents who frequently use their communication devices, four responded that they were either “neutral,” “somewhat uncomfortable,” or “very uncomfortable” (the lowest three ratings on a five-point scale) with spouses attempting to help them communicate or communicate faster and 5 of the 6 respondents indicated the same for close friends (all communication partner respondents were spouses or close friends; see Table 2). When broken down by the type of relationship between the AAC user and the communication partner, there was a general trend indicating AAC users are most comfortable with communication assistance from those partners whom they are closest to socially (Figure 1). Additionally, AAC users were most comfortable sharing information from their device to those partners with whom they are closest (Figure 2).</p>

      <h2>Discussion of Formative Study Findings</h2>
      <p>Several implications for design emerged from the results of our formative study. Of greatest salience was the AAC users’ desire to maximize their autonomy. Due to the fact that degenerative neuromuscular diseases like ALS gradually remove a person’s ability to both manipulate the surrounding world and communicate with other people, they cause patients to gradually become more dependent on others in order to survive. These diseases are not often associated with cognitive deficits, meaning that patients are fully aware of the losses they are experiencing. Through statements such as those in Table 2, respondents made it clear that any AAC technologies developed for them must either preserve or increase what little autonomy they still have. While in theory all AAC technologies could be considered as aiming to support autonomy to various extents, our results indicate that current solutions are insufficient in this respect, and may inadvertently reduce a user’s autonomy, such as by creating behaviors such as over-the-shoulder peeking that negatively impacted our participants. We captured this in the first design guideline for the development of our new system: The AAC system must preserve or increase users’ autonomy.</p>

      <p>Another interesting result was the disconnect between how communication partners view interactions versus how AAC users view interactions. The first observation related to this result was that in the responses in Table 1, half of the partners describe looking over the AAC user’s shoulder as they type. While this may have ramifications on the autonomy of the AAC user, it also indicates that the communication partner has highly limited awareness of the current communication (i.e., up-to-the-moment understanding of the communication being formed on the AAC device) without observing the visual output of the AAC device intended for the device’s user. A second observation related to this theme was that communication partners want to help the AAC users to communicate and they are comfortable doing so, whereas AAC users are uncomfortable with help being rendered since it encroaches upon their perceived autonomy. Together, these observations indicate that AAC systems should be designed according to the previously discussed guideline of autonomy, but should also attempt to balance this with engaging the communication partners in a way that capitalizes on their desire to help the AAC user and provides them with an accurate mental model of the interaction. We formulated this into the second design guideline for our new system: The AAC system should directly engage communication partners (in a manner that respects the autonomy of the AAC user).</p>

      <p>The final core result was the concept of privacy among various types of communication partners. The AAC users indicated that they felt most comfortable with receiving communication help from their closest communication partners (such as spouses) and least comfortable receiving such help from general acquaintances or strangers. This was echoed in the amount of information respondents indicated they were willing to share with communication partners. These observations align well with Blackstone’s Circles of Communication Partners paradigm [5]. Taking inspiration from this paradigm, we synthesized these observations into the third design guideline for our new system: If the AAC system engages communication partners by sharing communication data, it must allow the AAC user to control how information is shared.</p>
      
      <figure style="float: column-top;">
        <img src="img/figure2.png" id="figure2" style="width: 80%;">
        <figcaption>Subjective ratings of AAC users' comfort with sharing AAC device information with communication partners before choosing to render speech audibly. 0 is "Share Nothing," 1 is “Share Full Thoughts,” 2 is “Share Words,” 3 is “Share Characters,” and 4 is “Share Everything.” Bars indicate standard error.</figcaption>
      </figure>
    </section>

    <h1></h1>
    <section>
      <p></p>
      <p></p>
      <p></p>
      <p></p>
      <p></p>
      <p></p>
    </section>

    <h1></h1>
    <section>
      <p></p>
      <p></p>
      <p></p>
      <p></p>
      <p></p>
      <p></p>
    </section>

    <h1></h1>
    <section>
      <p></p>
      <p></p>
      <p></p>
      <p></p>
      <p></p>
      <p></p>
    </section>

    <h1></h1>
    <section>
      <p></p>
      <p></p>
      <p></p>
      <p></p>
      <p></p>
      <p></p>
    </section>

    <h1 id="typesettext">Typeset Text</h1>
    <section>
      <h2 id="normalorbodytext">Normal or Body Text</h2>
      <p>Please use a 9-point Times Roman font, or other Roman font with serifs, as close as possible in appearance to Times Roman in which these guidelines have been set. The goal is to have a 9-point text, as you see here. Please use sans-serif or non-proportional fonts only for special purposes, such as distinguishing source code text. If Times Roman is not available, try the font named Computer Modern Roman. On a Macintosh, use the font named Times.  Right margins should be justified, not ragged.</p>

      <h2>Titles and Authors</h2>
      <p>The title (Helvetica 18-point bold), authors' names (Helvetica 12-point) and affiliations (Helvetica 10-point) run across the full width of the page – one column wide. We also recommend phone number (Helvetica 10-point) and e-mail address (Helvetica 12-point). See the top of this page for three addresses. If only one address is needed, center all address text. For two addresses, use two centered tabs, and so on. For more than three authors, you may have to improvise.<span class="footnote">If necessary, you may place some address information in a footnote, or in a named section at the end of your paper.</span></p>

      <h2>First Page Copyright Notice</h2>
      <p>Please leave 3.81 cm (1.5") of blank text box at the bottom of the left column of the first page for the copyright notice.</p>

      <h2>Subsequent Pages</h2>
      <p>For pages other than the first page, start at the top of the page, and continue in double-column format.  The two columns on the last page should be as close to equal length as possible.</p>

      <table>
        <caption>Table captions should be placed above the table</caption>
        <thead>
          <tr>
            <th>Graphics</th>
            <th>Top</th>
            <th>In-between</th>
            <th>Bottom</th>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td>Tables</td>
            <td>End</td>
            <td>Last</td>
            <td>First</td>
          </tr>
          <tr>
            <td>Figures</td>
            <td>Good</td>
            <td>Similar</td>
            <td>Very well</td>
          </tr>
        </tbody>
      </table>

      <h2>References and Citations</h2>
      <p>Footnotes should be Times New Roman 9-point, and justified to the full width of the column.</p>
      <p>Use the <q>ACM Reference format</q> for references – that is, a numbered list at the end of the article, ordered alphabetically and formatted accordingly. See examples of some typical reference types, in the new <q>ACM Reference format</q>, at the end of this document. Within this template, use the style named <em>references</em> for the text. Acceptable abbreviations, for journal names, can be found here: <a href="http://library.caltech.edu/reference/abbreviations/">http://library.caltech.edu/reference/abbreviations/</a>. Word may try to automatically ‘underline’ hotlinks in your references, the correct style is NO underlining.</p>
      <p>The references are also in 9 pt., but that section (see Section <a href="#references" class="section"></a>) is ragged right. References should be published materials accessible to the public. Internal technical reports may be cited only if they are easily accessible (i.e. you can give the address to obtain the report within your citation) and may be obtained by any reader. Proprietary information may not be cited. Private communications should be acknowledged, not referenced (e.g., <q>[Robertson, personal communication]</q>).</p>

      <h2>Page Numbering, Headers and Footers</h2>
      <p>Do not include headers, footers or page numbers in your submission. These will be added when the publications are assembled.</p>
    </section>

    <h1>Figures/Captions</h1>
    <section>
      <p>Place Tables/Figures/Images in text as close to the reference as possible (see <a href="#figure1" class="figure"></a>). It may extend across both columns to a maximum width of 17.78 cm (7”).</p>
      <p>Captions should be Times New Roman 9-point bold. They should be numbered (e.g., <q>Table 1</q> or <q>Figure 2</q>), please note that the word for Table and Figure are spelled out. Figure’s captions should be centered beneath the image or picture, and Table captions should be centered above the table body.</p>
    </section>

    <h1>Sections</h1>
    <section>
      <p>The heading of a section should be in Times New Roman 12-point bold in all-capitals flush left with an additional 6-points of white space above the section head.  Sections and subsequent sub- sections should be numbered and flush left. For a section head and a subsection head together (such as Section <a href="#typesettext" class="section"></a> and subsection <a href="#normalorbodytext" class="subsection"></a>), use no additional space above the subsection head.</p>

      <h2>Subsections</h2>
      <p>The heading of subsections should be in Times New Roman 12-point bold with only the initial letters capitalized. (Note: For subsections and subsubsections, a word like <em>the</em> or <em>a</em> is not capitalized unless it is the first word of the header.)</p>

      <h3>Subsubsections</h3>
      <p>The heading for subsubsections should be in Times New Roman 11-point italic with initial letters capitalized and 6-points of white space above the subsubsection head.</p>

      <h4>Subsubsections</h4>
      <p>The heading for subsubsections should be in Times New Roman 11-point italic with initial letters capitalized.</p>

      <h4>Subsubsections</h4>
      <p>The heading for subsubsections should be in Times New Roman 11-point italic with initial letters capitalized.</p>
    </section>

    <h1>Acknowledgements</h1>
    <section>
      <p>Our thanks to ACM SIGCHI for allowing us to modify templates they had developed.</p>
    </section>

    <h4>Subsubsections</h4>

    <h1 id="references">References</h1>
    <section>
      <cite id="bowman93">Bowman, M., Debray, S. K., and Peterson, L. L. 1993. Reasoning about naming systems. <em>ACM Trans. Program. Lang. Syst.</em> 15, 5 (Nov. 1993), 795-825. DOI= <a href="http://doi.acm.org/10.1145/161468.16147">http://doi.acm.org/10.1145/161468.16147</a>.</cite>

      <cite id="ding97">Ding, W. and Marchionini, G. 1997. <em>A Study on Video Browsing Strategies</em>. Technical Report. University of Maryland at College Park.</cite>

      <cite id="frohlich00">Fröhlich, B. and Plate, J. 2000. The cubic mouse: a new device for three-dimensional input. In <em>Proceedings of the SIGCHI Conference on Human Factors in Computing Systems</em> (The Hague, The Netherlands, April 01 - 06, 2000). CHI '00. ACM, New York, NY, 526-531. DOI= <a href="http://doi.acm.org/10.1145/332040.332491">http://doi.acm.org/10.1145/332040.332491</a>.</cite>

      <cite id="tavel07">Tavel, P. 2007. <em>Modeling and Simulation Design</em>. AK Peters Ltd., Natick, MA.</cite>

      <cite id="sannella94">Sannella, M. J. 1994. <em>Constraint Satisfaction and Debugging for Interactive User Interfaces</em>. Doctoral Thesis. UMI Order Number: UMI Order No. GAX95-09398., University of Washington.</cite>

      <cite id="forman03">Forman, G. 2003. An extensive empirical study of feature selection metrics for text classification. <em>J. Mach. Learn. Res.</em> 3 (Mar. 2003), 1289-1305.</cite>

      <cite id="brown03">Brown, L. D., Hua, H., and Gao, C. 2003. A widget framework for augmented interaction in SCAPE. In <em>Proceedings of the 16th Annual ACM Symposium on User Interface Software and Technology</em> (Vancouver, Canada, November 02 - 05, 2003). UIST '03. ACM, New York, NY, 1-10. DOI= <a href="http://doi.acm.org/10.1145/964696.964697">http://doi.acm.org/10.1145/964696.964697</a>.</cite>

      <cite id="yu06">Yu, Y. T. and Lau, M. F. 2006. A comparison of MC/DC, MUMCUT and several other coverage criteria for logical decisions. <em>J. Syst. Softw.</em> 79, 5 (May. 2006), 577-590. DOI= <a href="http://dx.doi.org/10.1016/j.jss.2005.05.030">http://dx.doi.org/10.1016/j.jss.2005.05.030</a>.</cite>

      <cite id="spector89">Spector, A. Z. 1989. Achieving application requirements. In <em>Distributed Systems</em>, S. Mullender, Ed. ACM Press Frontier Series. ACM, New York, NY, 19-33. DOI= <a href="http://doi.acm.org/10.1145/90417.90738">http://doi.acm.org/10.1145/90417.90738</a>.</cite>

      <cite id="park13">Park, T. H., Saxena, A., Jagannath, S., Wiedenbeck, S., and Forte, A. 2013. Towards a taxonomy of errors in HTML and CSS. In <em>Proceedings of the ACM International Computing Education Research Conference</em> (San Diego, USA, August 12 - 14, 2013). ICER '13. ACM, New York, NY, 75-82. DOI= <a href="http://dx.doi.org/10.1145/2493394.2493405">http://dx.doi.org/10.1145/2493394.2493405</a>.</cite>
    </section>

    <!--<div class="reminder col-span">Columns on Last Page Should Be Made As Close As Possible to Equal Length</div>-->

    <!--<script src="../../node_modules/css-polyfills/dist/css-polyfills.js"></script>-->
  </body>
</html>